"""
Generated by Codeium
Improved by talentedbug

Please be aware of potential copyright risks

Prompt 1:

Please write a Python script that:
- Receive a number as an argument `begin_num`
- Or if there's no argument, find out the maximum number of directory names in `img`, and delete this one directory, then use the number as `begin_num`
- Get the HTML content of `https://www.xiurenwang.cc/[begin_num].html`
- Use RegEx expression to match `(?<=href=")\/\/ooo111\.ka123\.sbs\/pic\/.*?\/.*?\/.*?\.jpg`
- The matched URLs have prefix `//`, and add a protocol head `https:` to it
- This URL has a trailing `[img_num].jpg`, and download it into directory `img/[begin_num]/[img_num].jpg`
- Then increase `img_num` and download it in this way until the URL returns an error
- Decrease `img_num` from the original number and do the same
- Increase `begin_num`, and repeat the above steps
- If failing to download a page, skip to the next page

Prompt 2:

All the directories mentioned may not exist. It should be created if not present. Also in the procedure of finding the greatest number, it should handle the case that the directory does not exist, and use 13121 as the starting number.

Prompt 3:

Please add a referer header `Referer: https://www.xiurenwang.cc/[begin_num].html` when downloading images and add UA `Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/ [version number] Safari/537.36` to any downloads.

Prompt 4:

Add a UA when downloading pages too.

Prompt 5:

Please make the code allow insecure ssl content to be downloaded, and supress any warning.

Prompt 6:

Please make the download_image function:
- Save image with its initial number in the URL.
- Only save the first link matched by RegEx as example, and then *increase* and decrease the number in the URL, then download it.

Prompt 7:

Please don't set a limit for images that are downloaded. Instead, stop when an error occurs.

"""

import os
import re
import requests
from urllib.parse import urljoin
import warnings

def get_max_dir_num():
    img_dir = 'img'
    if not os.path.exists(img_dir):
        os.makedirs(img_dir)
    
    max_num = 13121
    for dir_name in os.listdir(img_dir):
        try:
            num = int(dir_name)
            if num > max_num:
                max_num = num
        except ValueError:
            pass
    return max_num

def download_images(begin_num):
    url = f'https://www.xiurenwang.cc/{begin_num}.html'
    print(f"[Info] Page URL: {url}")
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    response = requests.get(url, headers=headers)
    if response.status_code != 200:
        print(f'[Error] Failed to download page {begin_num}: Code {response.status_code}')
        return

    html = response.text
    pattern = r'(?<=href=")//ooo111\.ka123\.sbs/pic/.*?/.*?/.*?\.jpg'
    matches = re.findall(pattern, html)

    if not matches:
        print(f'[Error] Failed to download page {begin_num}: No images found')
        return

    initial_img_url = urljoin('https:', matches[0])
    initial_img_num = int(initial_img_url.split('/')[-1].split('.')[0])

    img_path = f'img/{begin_num}/{initial_img_num}.jpg'
    os.makedirs(os.path.dirname(img_path), exist_ok=True)

    headers = {
        'Referer': url,
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }

    # Download images with increasing numbers
    for i in range(initial_img_num, initial_img_num + 1200):  # adjust the range as needed
        img_url = initial_img_url.replace(f'{initial_img_num}.jpg', f'{i}.jpg')
        response = requests.get(img_url, headers=headers, verify=False)
        if response.status_code != 200:
            print(f"[Error] Failed to download image {img_url}: Code {response.status_code}")
            print("[Info] Increament terminated")
            break
        img_path = f'img/{begin_num}/{i}.jpg'
        with open(img_path, 'wb') as f:
            f.write(response.content)
        print(f"[Info] Downloaded image {img_url} to {img_path}")
        os.system(f"jpegoptim {img_path} -m40 -q")
        if os.popen(f"identify -format '%w' {img_path}").read() > 1000 or os.popen(f"identify -format '%h' {img_path}").read() > 1000:
            os.system(f"convert -resize 50% {img_path} {img_path}")
        print(f"[Info] Compressed image {img_path}")

    # Download images with decreasing numbers
    for i in range(initial_img_num - 1, 0, -1):  # adjust the range as needed
        img_url = initial_img_url.replace(f'{initial_img_num}.jpg', f'{i}.jpg')
        response = requests.get(img_url, headers=headers, verify=False)
        if response.status_code != 200:
            print(f"[Error] Failed to download image {img_url}: Code {response.status_code}")
            print("[Info] Decreament terminated")
            break
        img_path = f'img/{begin_num}/{i}.jpg'
        with open(img_path, 'wb') as f:
            f.write(response.content)
        print(f"[Info] Downloaded image {img_url} to {img_path}")

def main():
    import sys
    if len(sys.argv) > 1:
        begin_num = int(sys.argv[1])
    else:
        max_dir_num = get_max_dir_num()
        if max_dir_num > 13121:
            begin_num = max_dir_num
        else:
            begin_num = max_dir_num
    if begin_num == 13121:
        print(f"[Info] Use default begin_num {begin_num}")
    elif len(sys.argv) > 1:
        print(f"[Info] Use argument begin_num {begin_num}")
    else:
        print(f"[Info] Use resuming begin_num {begin_num}")

    current_max = 16466
    warnings.filterwarnings("ignore")
    while begin_num <= current_max:
        print(f"[Info] Proceeding page {begin_num}")
        download_images(begin_num)
        begin_num += 1

if __name__ == '__main__':
    main()
