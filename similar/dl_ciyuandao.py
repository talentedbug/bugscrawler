"""
Generated by Microsoft Copilot
Improved by talentedbug

Please be aware of potential copyright issues

This is a crawler for ciyuandao.com based on the one for Xiuren. Prompts for 
minor edits are omitted
"""

import os
import re
import requests
from urllib.parse import urljoin
import warnings

def get_max_dir_num():
    img_dir = 'img'
    if not os.path.exists(img_dir):
        os.makedirs(img_dir)
    
    max_num = 3
    for dir_name in os.listdir(img_dir):
        try:
            num = int(dir_name)
            if num > max_num:
                max_num = num
        except ValueError:
            pass
    return max_num

def download_images(begin_num):
    url = f'http://ciyuandao.com/photo/show/{begin_num}'
    print(f"[Info] Page URL: {url}")
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    response = requests.get(url, headers=headers)
    if response.status_code != 200:
        print(f'[Error] Failed to download page {begin_num}: Code {response.status_code}')
        return

    html = response.text
    pattern = r'(?<=<a href="javascript:;"><img src=")http:\/\/img\.ciyuandao\.com\/history\/.*?\.jpg(?=\?)'
    matches = re.findall(pattern, html)

    if not matches:
        print(f'[Error] Failed to download page {begin_num}: No images found')
        return

    initial_img_num = 1

    img_path = f'img/{begin_num}/{initial_img_num}.jpg'
    os.makedirs(os.path.dirname(img_path), exist_ok=True)

    headers = {
        'Referer': url,
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }

    # Download images with increasing numbers
    for img_url in matches:  # adjust the range as needed
        response = requests.get(img_url, headers=headers, verify=False)
        if response.status_code != 200:
            print(f"[Error] Failed to download image {img_url}: Code {response.status_code}")
            continue
        img_path = f'img/{begin_num}/{initial_img_num}.jpg'
        with open(img_path, 'wb') as f:
            f.write(response.content)
        print(f"[Info] Downloaded image {img_url} to {img_path}")
        os.system(f"jpegoptim {img_path} -m40 -q")
        if int(os.popen(f"identify -format '%w' {img_path}").read()) > 1000 or int(os.popen(f"identify -format '%h' {img_path}").read()) > 1000:
            os.system(f"convert -resize 50% {img_path} {img_path}")
        print(f"[Info] Compressed image {img_path}")
        initial_img_num += 1

def main():
    import sys
    if len(sys.argv) > 1:
        begin_num = int(sys.argv[1])
    else:
        max_dir_num = get_max_dir_num()
        if max_dir_num > 13121:
            begin_num = max_dir_num
        else:
            begin_num = max_dir_num
    if begin_num == 13121:
        print(f"[Info] Use default begin_num {begin_num}")
    elif len(sys.argv) > 1:
        print(f"[Info] Use argument begin_num {begin_num}")
    else:
        print(f"[Info] Use resuming begin_num {begin_num}")

    current_max = 145850 
    warnings.filterwarnings("ignore")
    while begin_num <= current_max:
        print(f"[Info] Proceeding page {begin_num}")
        download_images(begin_num)
        begin_num += 1

if __name__ == '__main__':
    main()
