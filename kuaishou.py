"""
Generated by Microsoft Copilot
Improved by talentedbug

Be aware of potential copyright issues

This is a crawler for girl videos on Kuaishou through a public API

Prompt 1:

I've got an API address `https://api.lolimi.cn/API/xjj/t.php` that will return a json responce in such format:

```
[
    {
        "code": 200,
        "msg": "https://alimov2.a.kwimgs.com/upic/2024/02/27/20/BMjAyNDAyMjcyMDI1MzRfMTg1MzI4MTI4MF8xMjYwOTU1OTQwNzJfMl8z_b_B258a82e2f527f8c5795423bf7b24dc64.mp4?clientCacheKey=3x9bbaddiprccs2_b.mp4&tt=b&di=78e498d6&bp=13414\n"
    }
]
```

... in which `msg` is a random URL.

Now I'd like you to write a Python script, that:

- Get the json from the API address.
- Check if the format is correct, if `code` is `200`, and if `msg` is a valid URL.
- If so, strip any parameters from the URL.
- Check again if the URL is valid and is a URL to an mp4 file.
- If so, download it into `img` directory in the working directory.
- If any error occurs, skip.
- Loop back to the first step. The times of looping should be defined in a variable.

Please try to make the code modulized and handle as many exceptions as possible. The handling method is to skip the current action and go to the next get.

Prompt 2:

Please make output information starting in "[Warning]" or "[Info]". Also name the saved files in numeric order.

Prompt 3:

Please make it sent with a common UA.

"""

import requests
import validators
import os
from urllib.parse import urlparse, urlunparse

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36'
}

def fetch_json(api_url):
    try:
        response = requests.get(api_url, headers=headers)
        response.raise_for_status()
        return response.json()
    except requests.RequestException as e:
        print(f"[Warning] Request error: {e}")
        return None

def is_valid_url(url):
    return validators.url(url)

def strip_url_params(url):
    parsed_url = urlparse(url)
    stripped_url = urlunparse((parsed_url.scheme, parsed_url.netloc, parsed_url.path, '', '', ''))
    return stripped_url

def download_file(url, directory, file_number):
    try:
        if not os.path.exists(directory):
            os.makedirs(directory)
        
        file_name = os.path.join(directory, f"{file_number}.mp4")
        with requests.get(url, stream=True, headers=headers) as r:
            r.raise_for_status()
            with open(file_name, 'wb') as f:
                for chunk in r.iter_content(chunk_size=8192):
                    f.write(chunk)
        print(f"[Info] Downloaded: {file_name}")
    except requests.RequestException as e:
        print(f"[Warning] Download error: {e}")

def main(api_url, loop_times):
    for i in range(loop_times):
        data = fetch_json(api_url)
        if data and isinstance(data, list):
            for item in data:
                if item.get('code') == 200 and 'msg' in item:
                    msg_url = item['msg'].strip()
                    if is_valid_url(msg_url):
                        stripped_url = strip_url_params(msg_url)
                        if is_valid_url(stripped_url) and stripped_url.endswith('.mp4'):
                            download_file(stripped_url, 'img', i+1)
                        else:
                            print("[Warning] Invalid stripped URL or not an mp4 file.")
                    else:
                        print("[Warning] Invalid URL in 'msg'.")
                else:
                    print("[Warning] Invalid data format or code not 200.")
        else:
            print("[Warning] Invalid JSON data.")

if __name__ == "__main__":
    api_url = "https://api.lolimi.cn/API/xjj/t.php"
    loop_times = 10  # Define the number of times to loop
    main(api_url, loop_times)
